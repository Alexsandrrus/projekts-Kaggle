{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":26266,"databundleVersionId":2030504,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/klyushnik/roc-auc0-85153?scriptVersionId=262540514\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-18T06:45:05.079443Z","iopub.execute_input":"2025-09-18T06:45:05.08103Z","iopub.status.idle":"2025-09-18T06:45:05.67736Z","shell.execute_reply.started":"2025-09-18T06:45:05.080983Z","shell.execute_reply":"2025-09-18T06:45:05.675655Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/advanced-dls-spring-2021/submission.csv\n/kaggle/input/advanced-dls-spring-2021/train.csv\n/kaggle/input/advanced-dls-spring-2021/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport warnings\nimport logging\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport shap\n\nfrom scipy import stats\nfrom scipy.optimize import minimize\nfrom scipy.stats import mstats\n\nimport catboost\nfrom catboost import CatBoostClassifier\nfrom catboost.utils import get_fnr_curve, get_fpr_curve, get_roc_curve\n\nimport lightgbm as lgb\nimport xgboost as xgb\n\nfrom mlxtend.classifier import StackingCVClassifier\n\nfrom sklearn.ensemble import (AdaBoostClassifier, BaggingClassifier,\n                              RandomForestClassifier, VotingClassifier)\nfrom sklearn.feature_selection import (SelectKBest, RFECV, chi2,\n                                       VarianceThreshold, SequentialFeatureSelector)\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (accuracy_score, classification_report,\n                             log_loss, roc_curve, roc_auc_score)\nfrom sklearn.model_selection import (KFold, RepeatedKFold,\n                                     RepeatedStratifiedKFold,\n                                     StratifiedGroupKFold, StratifiedKFold,\n                                     train_test_split)\nfrom sklearn.preprocessing import (LabelEncoder, QuantileTransformer, StandardScaler,\n                                   PowerTransformer, MaxAbsScaler, MinMaxScaler,\n                                   RobustScaler, PolynomialFeatures, OrdinalEncoder,\n                                   OneHotEncoder, FunctionTransformer, KBinsDiscretizer)\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.holtwinters import ExponentialSmoothing\n\nfrom category_encoders import TargetEncoder, MEstimateEncoder\n# from cuml.preprocessing import TargetEncoder\n\n# from imblearn.over_sampling import (SMOTE, ADASYN,\n#                                     BorderlineSMOTE, RandomOverSampler,\n#                                     KMeansSMOTE)\n# from imblearn.under_sampling import RandomUnderSampler\n# from imblearn.pipeline import make_pipeline, Pipeline\n\nimport optuna\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.initializers import Constant\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.metrics import AUC\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow import keras\n\nmpl.rcParams.update(mpl.rcParamsDefault)\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\nwarnings.filterwarnings('ignore')\n\nsns.set_context(\"notebook\", font_scale=1.2)\nsns.set_style(\"whitegrid\")\n\n%matplotlib inline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T06:45:05.678772Z","iopub.execute_input":"2025-09-18T06:45:05.679457Z","iopub.status.idle":"2025-09-18T06:45:15.854266Z","shell.execute_reply.started":"2025-09-18T06:45:05.679292Z","shell.execute_reply":"2025-09-18T06:45:15.853118Z"}},"outputs":[{"name":"stderr","text":"2025-09-18 06:45:12.183840: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1758177912.211726     195 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1758177912.219993     195 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def plot_numerical_features(df):\n    num_features = df.select_dtypes(include=[np.number]).columns\n    ncols = 2\n    nrows = (len(num_features) + ncols - 1) // ncols\n\n    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 6 * nrows))\n    axes = axes.flatten()\n\n    for i, feature in enumerate(num_features):\n        sns.histplot(df[feature], bins=30, kde=True, ax=axes[i], color='skyblue', edgecolor='black')\n        axes[i].set_title(f'Distribution of {feature}', fontsize=18, fontweight='bold')\n        axes[i].set_xlabel(feature, fontsize=14)\n        axes[i].set_ylabel('Frequency', fontsize=14)\n        axes[i].grid(True, linestyle='--', alpha=0.7)  \n\n        mean_value = df[feature].mean()\n        axes[i].axvline(mean_value, color='red', linestyle='--', label='Mean')\n        axes[i].legend()\n\n    plt.tight_layout()\n    plt.show()\n\ndef plot_numerical_boxplots(df):\n    num_features = df.select_dtypes(include=[np.number]).columns\n    ncols = 2\n    nrows = (len(num_features) + ncols - 1) // ncols\n\n    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 6 * nrows))\n    axes = axes.flatten()\n\n    for i, feature in enumerate(num_features):\n        sns.boxplot(x=df[feature], ax=axes[i], color='lightgreen')\n        axes[i].set_title(f'Boxplot of {feature}', fontsize=18, fontweight='bold')\n        axes[i].set_xlabel(feature, fontsize=14)\n        axes[i].grid(True, linestyle='--', alpha=0.7)  \n\n        median_value = df[feature].median()\n        axes[i].axvline(median_value, color='orange', linestyle='--', label='Median')\n        axes[i].legend()\n\n    plt.tight_layout()\n    plt.show()\n\ndef plot_qq_plot(df):\n    num_features = df.select_dtypes(include=[np.number]).columns\n    ncols = 2\n    nrows = (len(num_features) + ncols - 1) // ncols\n\n    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 6 * nrows))\n    axes = axes.flatten()\n\n    for i, feature in enumerate(num_features):\n        stats.probplot(df[feature], dist=\"norm\", plot=axes[i])\n        axes[i].set_title(f'QQ Plot of {feature}', fontsize=18, fontweight='bold')\n        axes[i].set_xlabel('Theoretical Quantiles', fontsize=14)\n        axes[i].set_ylabel('Sample Quantiles', fontsize=14)\n        axes[i].grid(True, linestyle='--', alpha= 0.7)  \n\n    plt.tight_layout()\n    plt.show()\n\ndef plot_correlation_matrix(df, method='spearman'):\n    num_df = df.select_dtypes(include=[np.number])\n    \n    corr = num_df.corr(method=method)\n    plt.figure(figsize=(14, 10))\n    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, cbar_kws={\"shrink\": .8}, linewidths=.5)\n    plt.title(f'Correlation Matrix ({method.capitalize()} Correlation)', fontsize=18, fontweight='bold')\n    plt.xticks(fontsize=12)\n    plt.yticks(fontsize=12)\n    plt.show()\n\ndef plot_pairplot(df):\n    num_features = df.select_dtypes(include=[np.number]).columns\n    sns.pairplot(df[num_features], diag_kind='kde', plot_kws={'alpha': 0.6, 'edgecolor': 'k'}, height=2.5)\n    plt.suptitle('Pairplot of Numerical Features', y=1.02, fontsize=18, fontweight='bold')\n    plt.show()\n\ndef plot_categorical_features(df, ncols=2, top_n=None):\n    cat_features = df.select_dtypes(include=[object]).columns\n    nrows = (len(cat_features) + ncols - 1) // ncols\n\n    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 6 * nrows))\n    axes = axes.flatten()\n\n    for i, feature in enumerate(cat_features):\n        if top_n is not None:\n            top_categories = df[feature].value_counts().nlargest(top_n).index\n            sns.countplot(data=df[df[feature].isin(top_categories)], y=feature, ax=axes[i], palette='viridis', order=top_categories)\n        else:\n            sns.countplot(data=df, y=feature, ax=axes[i], palette='viridis')\n        \n        axes[i].set_title(f'Count of {feature}', fontsize=18, fontweight='bold')\n        axes[i].set_xlabel('Count', fontsize=14)\n        axes[i].set_ylabel(feature, fontsize=14)\n        axes[i].tick_params(axis='y', rotation=0)\n        axes[i].grid(True, linestyle='--', alpha=0.7)  \n    for j in range(i + 1, len(axes)):\n        fig.delaxes(axes[j])\n\n    plt.tight_layout()\n    plt.show()\n\ndef PolynomialFeatures_labeled(input_df,power):\n   \n    poly = preprocessing.PolynomialFeatures(power)\n    output_nparray = poly.fit_transform(input_df)\n    powers_nparray = poly.powers_\n\n    input_feature_names = list(input_df.columns)\n    target_feature_names = [\"Constant Term\"]\n    for feature_distillation in powers_nparray[1:]:\n        intermediary_label = \"\"\n        final_label = \"\"\n        for i in range(len(input_feature_names)):\n            if feature_distillation[i] == 0:\n                continue\n            else:\n                variable = input_feature_names[i]\n                power = feature_distillation[i]\n                intermediary_label = \"%s+%d\" % (variable,power)\n                if final_label == \"\":         #If the final label isn't yet specified\n                    final_label = intermediary_label\n                else:\n                    final_label = final_label + \"x\" + intermediary_label\n        target_feature_names.append(final_label)\n    output_df = pd.DataFrame(output_nparray, columns = target_feature_names)\n    return output_df\n\ndef variance_threshold(df,th):\n    var_thres=VarianceThreshold(threshold=th)\n    var_thres.fit(df)\n    new_cols = var_thres.get_support()\n    return df.iloc[:,new_cols]\n   \ndef optimize_memory_usage(df, print_size=True):\n    \"\"\"\n    Optimizes memory usage in a DataFrame by downcasting numeric columns.\n\n    Parameters:\n        df (pd.DataFrame): The DataFrame to optimize.\n        print_size (bool): If True, prints memory usage before and after optimization.\n\n    Returns:\n        pd.DataFrame: The optimized DataFrame.\n    \"\"\"\n    # Types for optimization.\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    \n    # Memory usage size before optimize (Mb).\n    before_size = df.memory_usage().sum() / 1024**2\n    \n    for column in df.columns:\n        column_type = df[column].dtype\n        \n        if column_type in numerics:\n            try:\n                if str(column_type).startswith('int'):\n                    df[column] = pd.to_numeric(df[column], downcast='integer')\n                else:\n                    df[column] = pd.to_numeric(df[column], downcast='float')\n                logger.info(f\"Optimized column {column}: {column_type} -> {df[column].dtype}\")\n            except Exception as e:\n                logger.error(f\"Failed to optimize column {column}: {e}\")\n    \n    # Memory usage size after optimize (Mb).\n    after_size = df.memory_usage().sum() / 1024**2\n    \n    if print_size:\n        print(\n            'Memory usage size: before {:5.4f} Mb - after {:5.4f} Mb ({:.1f}%).'.format(\n                before_size, after_size, 100 * (before_size - after_size) / before_size\n            )\n        )\n    \n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T06:45:15.855585Z","iopub.execute_input":"2025-09-18T06:45:15.856487Z","iopub.status.idle":"2025-09-18T06:45:15.88787Z","shell.execute_reply.started":"2025-09-18T06:45:15.856457Z","shell.execute_reply":"2025-09-18T06:45:15.886535Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/advanced-dls-spring-2021/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/advanced-dls-spring-2021/test.csv\")\n\ndisplay(train.shape, test.shape)\ndisplay(train.info(), test.info())\n\n# test = test.drop(['id'], axis =1)\n# train = train.drop(['id'], axis =1)\n\ndisplay(train.describe().T)\ndisplay(test.describe().T)\n\nduplicates = train.duplicated()\nprint(f\"Number of duplicates: {duplicates.sum()}\")\n\nduplicates = test.duplicated()\nprint(f\"Number of duplicates: {duplicates.sum()}\")\n\nfor col in train.columns:\n    pct_missing = np.mean(train[col].isnull())\n    print('{} - {}%'.format(col, round(pct_missing*100)))\n\ndisplay(train.head(5))\n\nfor col in test.columns:\n    pct_missing = np.mean(test[col].isnull())\n    print('{} - {}%'.format(col, round(pct_missing*100)))\n\ntrain = optimize_memory_usage(train)\ntest = optimize_memory_usage(test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T06:45:15.888932Z","iopub.execute_input":"2025-09-18T06:45:15.889202Z","iopub.status.idle":"2025-09-18T06:45:16.070944Z","shell.execute_reply.started":"2025-09-18T06:45:15.889181Z","shell.execute_reply":"2025-09-18T06:45:16.06977Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"(5282, 20)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(1761, 19)"},"metadata":{}},{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5282 entries, 0 to 5281\nData columns (total 20 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   ClientPeriod              5282 non-null   int64  \n 1   MonthlySpending           5282 non-null   float64\n 2   TotalSpent                5282 non-null   object \n 3   Sex                       5282 non-null   object \n 4   IsSeniorCitizen           5282 non-null   int64  \n 5   HasPartner                5282 non-null   object \n 6   HasChild                  5282 non-null   object \n 7   HasPhoneService           5282 non-null   object \n 8   HasMultiplePhoneNumbers   5282 non-null   object \n 9   HasInternetService        5282 non-null   object \n 10  HasOnlineSecurityService  5282 non-null   object \n 11  HasOnlineBackup           5282 non-null   object \n 12  HasDeviceProtection       5282 non-null   object \n 13  HasTechSupportAccess      5282 non-null   object \n 14  HasOnlineTV               5282 non-null   object \n 15  HasMovieSubscription      5282 non-null   object \n 16  HasContractPhone          5282 non-null   object \n 17  IsBillingPaperless        5282 non-null   object \n 18  PaymentMethod             5282 non-null   object \n 19  Churn                     5282 non-null   int64  \ndtypes: float64(1), int64(3), object(16)\nmemory usage: 825.4+ KB\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1761 entries, 0 to 1760\nData columns (total 19 columns):\n #   Column                    Non-Null Count  Dtype  \n---  ------                    --------------  -----  \n 0   ClientPeriod              1761 non-null   int64  \n 1   MonthlySpending           1761 non-null   float64\n 2   TotalSpent                1761 non-null   object \n 3   Sex                       1761 non-null   object \n 4   IsSeniorCitizen           1761 non-null   int64  \n 5   HasPartner                1761 non-null   object \n 6   HasChild                  1761 non-null   object \n 7   HasPhoneService           1761 non-null   object \n 8   HasMultiplePhoneNumbers   1761 non-null   object \n 9   HasInternetService        1761 non-null   object \n 10  HasOnlineSecurityService  1761 non-null   object \n 11  HasOnlineBackup           1761 non-null   object \n 12  HasDeviceProtection       1761 non-null   object \n 13  HasTechSupportAccess      1761 non-null   object \n 14  HasOnlineTV               1761 non-null   object \n 15  HasMovieSubscription      1761 non-null   object \n 16  HasContractPhone          1761 non-null   object \n 17  IsBillingPaperless        1761 non-null   object \n 18  PaymentMethod             1761 non-null   object \ndtypes: float64(1), int64(2), object(16)\nmemory usage: 261.5+ KB\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"None"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"                  count       mean        std    min      25%   50%    75%  \\\nClientPeriod     5282.0  32.397009  24.550326   0.00   9.0000  29.0  55.00   \nMonthlySpending  5282.0  64.924754  30.176464  18.25  35.4625  70.4  90.05   \nIsSeniorCitizen  5282.0   0.159409   0.366092   0.00   0.0000   0.0   0.00   \nChurn            5282.0   0.262022   0.439776   0.00   0.0000   0.0   1.00   \n\n                    max  \nClientPeriod      72.00  \nMonthlySpending  118.75  \nIsSeniorCitizen    1.00  \nChurn              1.00  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ClientPeriod</th>\n      <td>5282.0</td>\n      <td>32.397009</td>\n      <td>24.550326</td>\n      <td>0.00</td>\n      <td>9.0000</td>\n      <td>29.0</td>\n      <td>55.00</td>\n      <td>72.00</td>\n    </tr>\n    <tr>\n      <th>MonthlySpending</th>\n      <td>5282.0</td>\n      <td>64.924754</td>\n      <td>30.176464</td>\n      <td>18.25</td>\n      <td>35.4625</td>\n      <td>70.4</td>\n      <td>90.05</td>\n      <td>118.75</td>\n    </tr>\n    <tr>\n      <th>IsSeniorCitizen</th>\n      <td>5282.0</td>\n      <td>0.159409</td>\n      <td>0.366092</td>\n      <td>0.00</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>Churn</th>\n      <td>5282.0</td>\n      <td>0.262022</td>\n      <td>0.439776</td>\n      <td>0.00</td>\n      <td>0.0000</td>\n      <td>0.0</td>\n      <td>1.00</td>\n      <td>1.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"                  count       mean        std    min    25%    50%   75%  \\\nClientPeriod     1761.0  32.293583  24.593736   0.00   9.00  29.00  56.0   \nMonthlySpending  1761.0  64.272601  29.832517  18.55  35.65  70.05  89.4   \nIsSeniorCitizen  1761.0   0.170358   0.376054   0.00   0.00   0.00   0.0   \n\n                    max  \nClientPeriod      72.00  \nMonthlySpending  117.35  \nIsSeniorCitizen    1.00  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ClientPeriod</th>\n      <td>1761.0</td>\n      <td>32.293583</td>\n      <td>24.593736</td>\n      <td>0.00</td>\n      <td>9.00</td>\n      <td>29.00</td>\n      <td>56.0</td>\n      <td>72.00</td>\n    </tr>\n    <tr>\n      <th>MonthlySpending</th>\n      <td>1761.0</td>\n      <td>64.272601</td>\n      <td>29.832517</td>\n      <td>18.55</td>\n      <td>35.65</td>\n      <td>70.05</td>\n      <td>89.4</td>\n      <td>117.35</td>\n    </tr>\n    <tr>\n      <th>IsSeniorCitizen</th>\n      <td>1761.0</td>\n      <td>0.170358</td>\n      <td>0.376054</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>1.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"Number of duplicates: 14\nNumber of duplicates: 3\nClientPeriod - 0%\nMonthlySpending - 0%\nTotalSpent - 0%\nSex - 0%\nIsSeniorCitizen - 0%\nHasPartner - 0%\nHasChild - 0%\nHasPhoneService - 0%\nHasMultiplePhoneNumbers - 0%\nHasInternetService - 0%\nHasOnlineSecurityService - 0%\nHasOnlineBackup - 0%\nHasDeviceProtection - 0%\nHasTechSupportAccess - 0%\nHasOnlineTV - 0%\nHasMovieSubscription - 0%\nHasContractPhone - 0%\nIsBillingPaperless - 0%\nPaymentMethod - 0%\nChurn - 0%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"   ClientPeriod  MonthlySpending TotalSpent     Sex  IsSeniorCitizen  \\\n0            55            19.50    1026.35    Male                0   \n1            72            25.85     1872.2    Male                0   \n2             1            75.90       75.9    Male                0   \n3            32            79.30       2570  Female                1   \n4            60           115.25    6758.45  Female                0   \n\n  HasPartner HasChild HasPhoneService HasMultiplePhoneNumbers  \\\n0        Yes      Yes             Yes                      No   \n1        Yes       No             Yes                     Yes   \n2         No       No             Yes                      No   \n3        Yes       No             Yes                     Yes   \n4        Yes      Yes             Yes                     Yes   \n\n  HasInternetService HasOnlineSecurityService      HasOnlineBackup  \\\n0                 No      No internet service  No internet service   \n1                 No      No internet service  No internet service   \n2        Fiber optic                       No                   No   \n3        Fiber optic                       No                   No   \n4        Fiber optic                      Yes                  Yes   \n\n   HasDeviceProtection HasTechSupportAccess          HasOnlineTV  \\\n0  No internet service  No internet service  No internet service   \n1  No internet service  No internet service  No internet service   \n2                   No                  Yes                   No   \n3                  Yes                   No                   No   \n4                  Yes                  Yes                  Yes   \n\n  HasMovieSubscription HasContractPhone IsBillingPaperless  \\\n0  No internet service         One year                 No   \n1  No internet service         Two year                 No   \n2                   No   Month-to-month                Yes   \n3                   No   Month-to-month                 No   \n4                  Yes         Two year                 No   \n\n             PaymentMethod  Churn  \n0             Mailed check      0  \n1  Credit card (automatic)      0  \n2         Electronic check      1  \n3             Mailed check      0  \n4  Credit card (automatic)      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ClientPeriod</th>\n      <th>MonthlySpending</th>\n      <th>TotalSpent</th>\n      <th>Sex</th>\n      <th>IsSeniorCitizen</th>\n      <th>HasPartner</th>\n      <th>HasChild</th>\n      <th>HasPhoneService</th>\n      <th>HasMultiplePhoneNumbers</th>\n      <th>HasInternetService</th>\n      <th>HasOnlineSecurityService</th>\n      <th>HasOnlineBackup</th>\n      <th>HasDeviceProtection</th>\n      <th>HasTechSupportAccess</th>\n      <th>HasOnlineTV</th>\n      <th>HasMovieSubscription</th>\n      <th>HasContractPhone</th>\n      <th>IsBillingPaperless</th>\n      <th>PaymentMethod</th>\n      <th>Churn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>55</td>\n      <td>19.50</td>\n      <td>1026.35</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No internet service</td>\n      <td>No internet service</td>\n      <td>No internet service</td>\n      <td>No internet service</td>\n      <td>No internet service</td>\n      <td>No internet service</td>\n      <td>One year</td>\n      <td>No</td>\n      <td>Mailed check</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>72</td>\n      <td>25.85</td>\n      <td>1872.2</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No internet service</td>\n      <td>No internet service</td>\n      <td>No internet service</td>\n      <td>No internet service</td>\n      <td>No internet service</td>\n      <td>No internet service</td>\n      <td>Two year</td>\n      <td>No</td>\n      <td>Credit card (automatic)</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>75.90</td>\n      <td>75.9</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Fiber optic</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>Yes</td>\n      <td>Electronic check</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>32</td>\n      <td>79.30</td>\n      <td>2570</td>\n      <td>Female</td>\n      <td>1</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Fiber optic</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Month-to-month</td>\n      <td>No</td>\n      <td>Mailed check</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>60</td>\n      <td>115.25</td>\n      <td>6758.45</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Fiber optic</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Two year</td>\n      <td>No</td>\n      <td>Credit card (automatic)</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"ClientPeriod - 0%\nMonthlySpending - 0%\nTotalSpent - 0%\nSex - 0%\nIsSeniorCitizen - 0%\nHasPartner - 0%\nHasChild - 0%\nHasPhoneService - 0%\nHasMultiplePhoneNumbers - 0%\nHasInternetService - 0%\nHasOnlineSecurityService - 0%\nHasOnlineBackup - 0%\nHasDeviceProtection - 0%\nHasTechSupportAccess - 0%\nHasOnlineTV - 0%\nHasMovieSubscription - 0%\nHasContractPhone - 0%\nIsBillingPaperless - 0%\nPaymentMethod - 0%\nMemory usage size: before 0.8061 Mb - after 0.6802 Mb (15.6%).\nMemory usage size: before 0.2554 Mb - after 0.2252 Mb (11.8%).\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"class DataPreprocessor:\n    def __init__(self):\n        self.scaler = StandardScaler()\n        self.is_fitted = False\n        \n    def fit_transform(self, df, target_present=True):\n        \"\"\"Обучение и преобразование тренировочных данных\"\"\"\n        df_processed = self._basic_preprocessing(df)\n        \n        # Масштабирование числовых признаков\n        numerical_columns = ['ClientPeriod', 'MonthlySpending', 'TotalSpent', \n                            'SpentPerMonth', 'SpendingRatio']\n        \n        df_processed[numerical_columns] = self.scaler.fit_transform(df_processed[numerical_columns])\n        self.is_fitted = True\n        \n        if target_present and 'Churn' in df_processed.columns:\n            return df_processed.drop('Churn', axis=1), df_processed['Churn']\n        else:\n            return df_processed\n        \n    def transform(self, df, target_present=True):\n        \"\"\"Преобразование тестовых данных\"\"\"\n        if not self.is_fitted:\n            raise ValueError(\"Сначала вызовите fit_transform на тренировочных данных\")\n            \n        df_processed = self._basic_preprocessing(df)\n        \n        numerical_columns = ['ClientPeriod', 'MonthlySpending', 'TotalSpent', \n                            'SpentPerMonth', 'SpendingRatio']\n        \n        df_processed[numerical_columns] = self.scaler.transform(df_processed[numerical_columns])\n        \n        if target_present and 'Churn' in df_processed.columns:\n            return df_processed.drop('Churn', axis=1), df_processed['Churn']\n        else:\n            return df_processed\n    \n    def _basic_preprocessing(self, df):\n        \"\"\"Базовая предобработка, общая для train и test\"\"\"\n        df_processed = df.copy()\n        \n        # Все шаги предобработки кроме масштабирования...\n        df_processed['TotalSpent'] = pd.to_numeric(df_processed['TotalSpent'], errors='coerce').fillna(0)\n        \n        binary_columns = [\n            'Sex', 'HasPartner', 'HasChild', 'HasPhoneService', \n            'HasMultiplePhoneNumbers', 'HasInternetService',\n            'HasOnlineSecurityService', 'HasOnlineBackup', \n            'HasDeviceProtection', 'HasTechSupportAccess',\n            'HasOnlineTV', 'HasMovieSubscription', \n            'HasContractPhone', 'IsBillingPaperless'\n        ]\n        \n        for col in binary_columns:\n            df_processed[col] = df_processed[col].str.lower()\n            df_processed[col] = df_processed[col].map({\n                'yes': 1, 'no': 0, 'male': 1, 'female': 0,\n                'one year': 1, 'two year': 1, 'month-to-month': 0,\n                'no internet service': 0\n            }).fillna(0).astype(int)\n        \n        payment_method_mapping = {\n            'Mailed check': 0, 'Credit card (automatic)': 1,\n            'Bank transfer (automatic)': 2, 'Electronic check': 3\n        }\n        \n        df_processed['PaymentMethod'] = df_processed['PaymentMethod'].map(\n            payment_method_mapping\n        ).fillna(0).astype(int)\n        \n        # Создание новых признаков\n        df_processed['SpentPerMonth'] = df_processed['TotalSpent'] / np.where(\n            df_processed['ClientPeriod'] > 0, \n            df_processed['ClientPeriod'], \n            1\n        )\n        \n        df_processed['SpendingRatio'] = df_processed['MonthlySpending'] / df_processed['SpentPerMonth'].replace(0, 1)\n        \n        return df_processed\n\n# Использование:\npreprocessor = DataPreprocessor()\n\n# Обработка тренировочных данных\nX, y = preprocessor.fit_transform(train)\n\n# Обработка тестовых данных (без целевой переменной)\ntest = preprocessor.transform(test, target_present=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T06:45:16.072255Z","iopub.execute_input":"2025-09-18T06:45:16.072654Z","iopub.status.idle":"2025-09-18T06:45:16.158801Z","shell.execute_reply.started":"2025-09-18T06:45:16.072632Z","shell.execute_reply":"2025-09-18T06:45:16.157763Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"X = variance_threshold(X,0.03)\nlist_name = (X.columns)\ntest = test[list_name]\n\ndisplay(X.shape, y.shape, test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T06:45:16.161457Z","iopub.execute_input":"2025-09-18T06:45:16.161799Z","iopub.status.idle":"2025-09-18T06:45:16.183781Z","shell.execute_reply.started":"2025-09-18T06:45:16.161774Z","shell.execute_reply":"2025-09-18T06:45:16.182785Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"(5282, 20)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(5282,)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(1761, 20)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"def create_ensemble_classification_auc(X, y, test_aligned, n_folds=7):\n    \"\"\"\n    Ансамбль моделей для классификации с использованием ROC-AUC score\n    \n    Parameters:\n    X (pd.DataFrame): Признаки train\n    y (pd.Series): Целевая переменная train\n    test_aligned (pd.DataFrame): Признаки test\n    n_folds (int): Количество фолдов для кросс-валидации\n    \n    Returns:\n    oof_df, predictions_df, model_info\n    \"\"\"\n    FOLDS = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n    \n    all_oof_proba = {}  # OOF вероятности для ROC-AUC\n    all_predictions_proba = {}  # Тестовые вероятности\n    models = []\n    \n    # CatBoost модели \n    models.append(('cat_1', CatBoostClassifier(verbose=0, random_state=42, \n                                                auto_class_weights='Balanced',\n                                                iterations=500,\n                                                learning_rate=0.05,\n                                                depth=7,\n                                                l2_leaf_reg=5)))\n    \n    models.append(('cat_2', CatBoostClassifier(verbose=0, random_state=42,\n                                                iterations=400,\n                                                learning_rate=0.1,\n                                                depth=4,\n                                                bootstrap_type='Bernoulli',\n                                                subsample=0.8)))\n    \n    models.append(('cat_3', CatBoostClassifier( verbose=0, random_state=42,\n                                                iterations=300,\n                                                learning_rate=0.03,\n                                                depth=10,\n                                                l2_leaf_reg=10,\n                                                grow_policy='Lossguide')))\n    \n    models.append(('cat_balanced', CatBoostClassifier(\n                                                        verbose=0, random_state=42, \n                                                        auto_class_weights='Balanced',\n                                                        iterations=1000,\n                                                        learning_rate=0.05,\n                                                        depth=7,\n                                                        l2_leaf_reg=5\n                                                        )))\n    \n    models.append(('cat_fast', CatBoostClassifier(\n                                                    verbose=0, random_state=42,\n                                                    iterations=300,\n                                                    learning_rate=0.1,\n                                                    depth=4,\n                                                    bootstrap_type='Bernoulli',\n                                                    subsample=0.8\n                                                )))\n    \n    models.append(('cat_deep', CatBoostClassifier(\n                                                    verbose=0, random_state=42,\n                                                    iterations=800,\n                                                    learning_rate=0.03,\n                                                    depth=10,\n                                                    l2_leaf_reg=10,\n                                                    grow_policy='Lossguide'\n                                                )))\n    \n    models.append(('cat_regularized', CatBoostClassifier(\n                                                            verbose=0, random_state=42,\n                                                            iterations=600,\n                                                            learning_rate=0.02,\n                                                            depth=6,\n                                                            l2_leaf_reg=20,\n                                                            border_count=128,\n                                                            random_strength=2\n                                                        )))\n    \n    models.append(('cat_high_lr', CatBoostClassifier(\n                                                        verbose=0, random_state=42,\n                                                        iterations=200,\n                                                        learning_rate=0.2,\n                                                        depth=5,\n                                                    )))\n    \n    # XGBoost модели\n    models.append(('xgb_1', xgb.XGBClassifier(random_state=42, n_jobs=1,\n                                                use_label_encoder=False, eval_metric='logloss',\n                                                n_estimators=300,\n                                                learning_rate=0.1,\n                                                max_depth=4,\n                                                booster='dart',\n                                                rate_drop=0.1)))\n    \n    models.append(('xgb_2', xgb.XGBClassifier( random_state=42, n_jobs=1,\n                                                use_label_encoder=False, eval_metric='logloss',\n                                                n_estimators=50,\n                                                learning_rate=0.02,\n                                                max_depth=7,\n                                                reg_alpha=1.0,\n                                                reg_lambda=2.0,\n                                                subsample=0.7)))\n    \n    models.append(('xgb_3', xgb.XGBClassifier( random_state=42, n_jobs=1,\n                                                use_label_encoder=False, eval_metric='logloss',\n                                                n_estimators=250,\n                                                learning_rate=0.1,\n                                                booster='gblinear',\n                                                updater='coord_descent')))\n\n    models.append(('xgb_balanced', xgb.XGBClassifier(\n                                                    random_state=42, n_jobs=1,\n                                                    use_label_encoder=False, eval_metric='logloss',\n                                                    n_estimators=100,\n                                                    learning_rate=0.05,\n                                                    max_depth=6,\n                                                    scale_pos_weight=len(y[y==0])/len(y[y==1]) if sum(y) > 0 else 1,\n                                                    subsample=0.8,\n                                                    colsample_bytree=0.8\n                                                )))\n    \n    models.append(('xgb_fast', xgb.XGBClassifier(\n                                                    random_state=42, n_jobs=1,\n                                                    use_label_encoder=False, eval_metric='logloss',\n                                                    n_estimators=300,\n                                                    learning_rate=0.1,\n                                                    max_depth=4,\n                                                    booster='dart',\n                                                    rate_drop=0.1\n                                                )))\n    \n    models.append(('xgb_deep', xgb.XGBClassifier(\n                                                    random_state=42, n_jobs=1,\n                                                    use_label_encoder=False, eval_metric='logloss',\n                                                    n_estimators=500,\n                                                    learning_rate=0.03,\n                                                    max_depth=12,\n                                                    min_child_weight=3,\n                                                    gamma=0.2\n                                                )))\n    \n    models.append(('xgb_regularized', xgb.XGBClassifier(\n                                                            random_state=42, n_jobs=1,\n                                                            use_label_encoder=False, eval_metric='logloss',\n                                                            n_estimators=800,\n                                                            learning_rate=0.02,\n                                                            max_depth=7,\n                                                            reg_alpha=1.0,\n                                                            reg_lambda=2.0,\n                                                            subsample=0.7\n                                                        )))\n    \n    models.append(('xgb_gblinear', xgb.XGBClassifier(\n                                                        random_state=42, n_jobs=1,\n                                                        use_label_encoder=False, eval_metric='logloss',\n                                                        n_estimators=500,\n                                                        learning_rate=0.1,\n                                                        booster='gblinear',\n                                                        updater='coord_descent'\n                                                    )))\n    \n    # LightGBM модели\n    models.append(('lgb_1', lgb.LGBMClassifier( verbose=-1,random_state=42, n_jobs=1,\n                                                n_estimators=300,\n                                                learning_rate=0.05,\n                                                num_leaves=63,\n                                                class_weight='balanced',\n                                                subsample=0.8,\n                                                colsample_bytree=0.8)))\n    \n    models.append(('lgb_2', lgb.LGBMClassifier(  verbose=-1, random_state=42, n_jobs=1,\n                                                    n_estimators=400,\n                                                    learning_rate=0.03,\n                                                    num_leaves=255,\n                                                    max_depth=-1,\n                                                    min_data_in_leaf=50,\n                                                    feature_fraction=0.7)))\n    \n    models.append(('lgb_3', lgb.LGBMClassifier( verbose=-1, random_state=42, n_jobs=1,\n                                                n_estimators=290,\n                                                learning_rate=0.02,\n                                                num_leaves=127,\n                                                reg_alpha=1.0,\n                                                reg_lambda=2.0,\n                                                subsample_freq=5)))\n\n    models.append(('lgb_balanced', lgb.LGBMClassifier(\n                                                        random_state=42, n_jobs=1,\n                                                        n_estimators=100,\n                                                        learning_rate=0.05,\n                                                        num_leaves=63,\n                                                        class_weight='balanced',\n                                                        subsample=0.8,\n                                                        colsample_bytree=0.8\n                                                    )))\n    \n    models.append(('lgb_fast', lgb.LGBMClassifier(\n                                                    random_state=42, n_jobs=1,\n                                                    n_estimators=300,\n                                                    learning_rate=0.1,\n                                                    num_leaves=31,\n                                                    boosting_type='dart',\n                                                    drop_rate=0.1\n                                                )))\n    \n    models.append(('lgb_large', lgb.LGBMClassifier(\n                                                    random_state=42, n_jobs=1,\n                                                    n_estimators=500,\n                                                    learning_rate=0.03,\n                                                    num_leaves=255,\n                                                    max_depth=-1,\n                                                    min_data_in_leaf=50,\n                                                    feature_fraction=0.7\n                                                )))\n    \n    models.append(('lgb_regularized', lgb.LGBMClassifier(\n                                                            random_state=42, n_jobs=1,\n                                                            n_estimators=800,\n                                                            learning_rate=0.02,\n                                                            num_leaves=127,\n                                                            reg_alpha=1.0,\n                                                            reg_lambda=2.0,\n                                                            subsample_freq=5\n                                                        )))\n    \n    models.append(('lgb_goss', lgb.LGBMClassifier(\n                                                    random_state=42, n_jobs=1,\n                                                    n_estimators=600,\n                                                    learning_rate=0.04,\n                                                    num_leaves=95,\n                                                    boosting_type='goss',\n                                                    top_rate=0.2,\n                                                    other_rate=0.1\n                                                )))\n    \n    models.append(('lgb_simple', lgb.LGBMClassifier(\n                                                        random_state=42, n_jobs=1,\n                                                        n_estimators=400,\n                                                        learning_rate=0.08,\n                                                        num_leaves=15,\n                                                        max_depth=4,\n                                                        min_child_samples=100\n                                                    )))\n\n    for name, model in models:\n        try:\n            print(f\"\\nTraining {name}...\")\n            oof_proba = np.zeros(len(X))  # OOF вероятности класса 1\n            pred_proba = np.zeros(len(test_aligned))  # Тестовые вероятности класса 1\n            \n            for fold, (trn_idx, val_idx) in enumerate(FOLDS.split(X, y)):\n                X_train, y_train = X.iloc[trn_idx], y.iloc[trn_idx]\n                X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n                \n                # Обучение модели\n                if name.startswith('cat'):\n                    model.fit(X_train, y_train, verbose=0)\n                else:\n                    model.fit(X_train, y_train)\n                \n                # Предсказания вероятностей для OOF\n                if hasattr(model, 'predict_proba'):\n                    val_proba = model.predict_proba(X_val)[:, 1]\n                    oof_proba[val_idx] = val_proba\n                    \n                    # Предсказания вероятностей для test\n                    test_fold_proba = model.predict_proba(test_aligned)[:, 1]\n                    pred_proba += test_fold_proba / FOLDS.n_splits\n                \n                # Расчет ROC-AUC для фолда\n                fold_auc = roc_auc_score(y_val, val_proba)\n                print(f'{name} - Fold {fold} ROC-AUC: {fold_auc:.4f}')\n            \n            # Сохраняем OOF вероятности\n            all_oof_proba[name] = oof_proba\n            \n            # Сохраняем тестовые вероятности\n            all_predictions_proba[name] = pred_proba\n            \n            # Полный ROC-AUC score\n            full_auc = roc_auc_score(y, oof_proba)\n            print(f'{name} - Full OOF ROC-AUC: {full_auc:.4f}')\n            \n        except Exception as e:\n            print(f\"Error training {name}: {str(e)}\")\n            continue\n    \n    # Проверка, что хотя бы одна модель обучилась\n    if not all_oof_proba:\n        print(\"Все модели завершились с ошибкой! Возвращаем None.\")\n        return None, None, None\n    \n    # Создаем DataFrame с результатами\n    oof_df = pd.DataFrame(all_oof_proba)\n    oof_df = oof_df.add_suffix('_proba')\n    \n    predictions_df = pd.DataFrame(all_predictions_proba)\n    predictions_df = predictions_df.add_suffix('_proba')\n    \n    # Добавляем целевые переменные\n    oof_df['target'] = y.values\n    \n    # Создаем бинарные предсказания на основе порога 0.5 (опционально)\n    for model_name in all_oof_proba.keys():\n        oof_df[f'{model_name}_pred'] = (oof_df[f'{model_name}_proba'] >= 0.5).astype(int)\n        predictions_df[f'{model_name}_pred'] = (predictions_df[f'{model_name}_proba'] >= 0.5).astype(int)\n    \n    model_info = {\n        'model_names': list(all_oof_proba.keys()),\n        'num_models': len(all_oof_proba),\n        'features_used': list(X.columns),\n        'metric_used': 'roc_auc',\n        'oof_auc_scores': {name: roc_auc_score(y, all_oof_proba[name]) for name in all_oof_proba.keys()}\n    }\n    \n    # Вывод среднего ROC-AUC\n    avg_auc = np.mean(list(model_info['oof_auc_scores'].values()))\n    print(f\"\\nAverage OOF ROC-AUC across all models: {avg_auc:.4f}\")\n    \n    return oof_df, predictions_df, model_info\n\n# Альтернативная версия с возвратом только вероятностей (без бинарных предсказаний)\ndef create_ensemble_classification_auc_proba_only(X, y, test_aligned, n_folds=7):\n    \"\"\"\n    Упрощенная версия, возвращающая только вероятности\n    \"\"\"\n    FOLDS = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n    \n    all_oof_proba = {}\n    all_predictions_proba = {}\n    models = []\n    \n    # Модели (можно настроить под конкретную задачу)\n    models.append(('cat', CatBoostClassifier(verbose=0, random_state=42)))\n    models.append(('xgb', xgb.XGBClassifier(random_state=42, n_jobs=1, use_label_encoder=False, eval_metric='logloss')))\n    models.append(('lgb', lgb.LGBMClassifier(random_state=42, n_jobs=1)))\n\n    for name, model in models:\n        try:\n            print(f\"\\nTraining {name}...\")\n            oof_proba = np.zeros(len(X))\n            pred_proba = np.zeros(len(test_aligned))\n            \n            for fold, (trn_idx, val_idx) in enumerate(FOLDS.split(X, y)):\n                X_train, y_train = X.iloc[trn_idx], y.iloc[trn_idx]\n                X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n                \n                if name.startswith('cat'):\n                    model.fit(X_train, y_train, verbose=0)\n                else:\n                    model.fit(X_train, y_train)\n                \n                val_proba = model.predict_proba(X_val)[:, 1]\n                oof_proba[val_idx] = val_proba\n                pred_proba += model.predict_proba(test_aligned)[:, 1] / FOLDS.n_splits\n                \n                fold_auc = roc_auc_score(y_val, val_proba)\n                print(f'{name} - Fold {fold} AUC: {fold_auc:.4f}')\n            \n            all_oof_proba[name] = oof_proba\n            all_predictions_proba[name] = pred_proba\n            \n            full_auc = roc_auc_score(y, oof_proba)\n            print(f'{name} - Full OOF AUC: {full_auc:.4f}')\n            \n        except Exception as e:\n            print(f\"Error training {name}: {str(e)}\")\n            continue\n    \n    if not all_oof_proba:\n        return None, None, None\n    \n    oof_df = pd.DataFrame(all_oof_proba)\n    predictions_df = pd.DataFrame(all_predictions_proba)\n    oof_df['target'] = y.values\n    \n    model_info = {\n        'model_names': list(all_oof_proba.keys()),\n        'auc_scores': {name: roc_auc_score(y, all_oof_proba[name]) for name in all_oof_proba.keys()}\n    }\n    \n    return oof_df, predictions_df, model_info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T06:45:16.184911Z","iopub.execute_input":"2025-09-18T06:45:16.185296Z","iopub.status.idle":"2025-09-18T06:45:16.227787Z","shell.execute_reply.started":"2025-09-18T06:45:16.18526Z","shell.execute_reply":"2025-09-18T06:45:16.226579Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Запуск ансамбля с ROC-AUC\noof_results, test_predictions, model_info = create_ensemble_classification_auc(\n    X, y, test, n_folds=5\n)\n\n# Анализ результатов\nif oof_results is not None:\n    print(\"\\n=== Результаты ансамбля ===\")\n    for model_name, auc_score in model_info['oof_auc_scores'].items():\n        print(f\"{model_name}: ROC-AUC = {auc_score:.4f}\")\n    \n    # Создание блендинга (усреднение вероятностей)\n    proba_columns = [col for col in test_predictions.columns if col.endswith('_proba')]\n    test_predictions['ensemble_proba'] = test_predictions[proba_columns].mean(axis=1)\n    test_predictions['ensemble_pred'] = (test_predictions['ensemble_proba'] >= 0.5).astype(int)\n    \n    print(f\"\\nEnsemble ROC-AUC: {np.mean(list(model_info['oof_auc_scores'].values())):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T06:45:16.228798Z","iopub.execute_input":"2025-09-18T06:45:16.229067Z"}},"outputs":[{"name":"stdout","text":"\nTraining cat_1...\ncat_1 - Fold 0 ROC-AUC: 0.8149\ncat_1 - Fold 1 ROC-AUC: 0.8229\ncat_1 - Fold 2 ROC-AUC: 0.8281\ncat_1 - Fold 3 ROC-AUC: 0.8584\ncat_1 - Fold 4 ROC-AUC: 0.8237\ncat_1 - Full OOF ROC-AUC: 0.8295\n\nTraining cat_2...\ncat_2 - Fold 0 ROC-AUC: 0.8134\ncat_2 - Fold 1 ROC-AUC: 0.8299\ncat_2 - Fold 2 ROC-AUC: 0.8328\ncat_2 - Fold 3 ROC-AUC: 0.8548\ncat_2 - Fold 4 ROC-AUC: 0.8295\ncat_2 - Full OOF ROC-AUC: 0.8319\n\nTraining cat_3...\ncat_3 - Fold 0 ROC-AUC: 0.8208\ncat_3 - Fold 1 ROC-AUC: 0.8316\ncat_3 - Fold 2 ROC-AUC: 0.8342\ncat_3 - Fold 3 ROC-AUC: 0.8672\ncat_3 - Fold 4 ROC-AUC: 0.8437\ncat_3 - Full OOF ROC-AUC: 0.8392\n\nTraining cat_balanced...\ncat_balanced - Fold 0 ROC-AUC: 0.8099\ncat_balanced - Fold 1 ROC-AUC: 0.8178\ncat_balanced - Fold 2 ROC-AUC: 0.8204\ncat_balanced - Fold 3 ROC-AUC: 0.8514\ncat_balanced - Fold 4 ROC-AUC: 0.8179\ncat_balanced - Full OOF ROC-AUC: 0.8234\n\nTraining cat_fast...\ncat_fast - Fold 0 ROC-AUC: 0.8154\ncat_fast - Fold 1 ROC-AUC: 0.8319\ncat_fast - Fold 2 ROC-AUC: 0.8362\ncat_fast - Fold 3 ROC-AUC: 0.8588\ncat_fast - Fold 4 ROC-AUC: 0.8343\ncat_fast - Full OOF ROC-AUC: 0.8352\n\nTraining cat_deep...\ncat_deep - Fold 0 ROC-AUC: 0.8070\ncat_deep - Fold 1 ROC-AUC: 0.8142\ncat_deep - Fold 2 ROC-AUC: 0.8233\ncat_deep - Fold 3 ROC-AUC: 0.8509\ncat_deep - Fold 4 ROC-AUC: 0.8260\ncat_deep - Full OOF ROC-AUC: 0.8243\n\nTraining cat_regularized...\ncat_regularized - Fold 0 ROC-AUC: 0.8220\ncat_regularized - Fold 1 ROC-AUC: 0.8359\ncat_regularized - Fold 2 ROC-AUC: 0.8377\ncat_regularized - Fold 3 ROC-AUC: 0.8693\ncat_regularized - Fold 4 ROC-AUC: 0.8478\ncat_regularized - Full OOF ROC-AUC: 0.8423\n\nTraining cat_high_lr...\nError training cat_high_lr: To employ param {'use_best_model': True} provide non-empty 'eval_set'.\n\nTraining xgb_1...\nxgb_1 - Fold 0 ROC-AUC: 0.8150\nxgb_1 - Fold 1 ROC-AUC: 0.8314\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"sample = pd.read_csv('/kaggle/input/advanced-dls-spring-2021/submission.csv')\nsample['Churn'] = test_predictions['ensemble_proba']\nsample.to_csv('submission.csv', index=False)\nsample.head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}