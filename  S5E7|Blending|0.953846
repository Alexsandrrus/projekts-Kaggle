{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91718,"databundleVersionId":12738969,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/klyushnik/s5e7-blending-0-974898?scriptVersionId=252784094\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-20T08:59:09.956647Z","execution_failed":"2025-07-21T10:59:32.495Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Predicting Personality Types: Introvert vs Extrovert\n### Kaggle Playground Series 2025 - EDA & Modeling Notebook\n\n## ðŸŽ¯ Competition Overview\n**Task:** Binary classification predicting personality type (Introvert/Extrovert) from social behavior traits  \n**Metric:** Accuracy Score  \n**Data:** Social interaction patterns and psychological trait measurements  \n\n```python\n# Sample submission format\nsubmission = pd.DataFrame({\n    'id': test_ids,\n    'Personality': predictions  # 'Introvert' or 'Extrovert'\n})\nsubmission.to_csv('submission.csv', index=False)","metadata":{}},{"cell_type":"markdown","source":"### ðŸ“Š Notebook Roadmap\n\n**1. Data Investigation**\n**ðŸ” Planned Checks:**\n\n- Missing value heatmap\n\n- Target distribution pie chart\n\n- Feature correlation matrix\n\n**2. Feature Engineering\nTransformations:**\n\n-Normalize numerical scales\n\n- Interaction terms creation\n\n**3. Model Pipeline**\n```python\nmodels = {\n    'CatBoostClassifier': CatBoostClassifier(),\n    'XGBoost': XGBClassifier(),\n    'LGBMClassifier': LGBMClassifier()\n}\n```\n\n**4. Evaluation\nValidation Strategy:**\n\n- Stratified 5-fold CV\n\n- Learning curves\n\n\n**ðŸ† Expected Outcomes\nBaseline model with >80% accuracy**\n\n**Feature importance visualization**\n\n**Optimized submission file**","metadata":{}},{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"!pip install -q scikit-learn imbalanced-learn\n!pip install -q scikeras\n!pip install -q sdv","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.495Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom matplotlib.pyplot import figure\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\nfrom scipy.stats import mstats\nfrom scipy.stats.mstats import winsorize\nfrom scipy.optimize import minimize\nfrom scipy.sparse import coo_matrix, hstack\nfrom sklearn.metrics import make_scorer\nfrom sklearn.model_selection import cross_val_score\nimport warnings\n\nfrom imblearn.over_sampling import (\nADASYN, \nSMOTE, \nKMeansSMOTE)\n\nfrom sklearn import preprocessing\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import (\n    LabelEncoder,\n    QuantileTransformer,\n    StandardScaler,\n    PowerTransformer,\n    MaxAbsScaler,\n    MinMaxScaler,\n    RobustScaler,\n    PolynomialFeatures,\n    OrdinalEncoder,\n    OneHotEncoder,\n    FunctionTransformer,\n    KBinsDiscretizer,\n)\nfrom sklearn.feature_selection import (\n    VarianceThreshold,\n    SelectKBest,\n    chi2,\n    SequentialFeatureSelector,\n)\nfrom sklearn.model_selection import (\n    StratifiedKFold,\n    KFold,\n    train_test_split,\n    cross_validate,\n)\nfrom sklearn.linear_model import (\n    LogisticRegression,\n)\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.ensemble import StackingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import (\n    RandomForestClassifier,\n    GradientBoostingClassifier,\n    AdaBoostClassifier,\n    HistGradientBoostingClassifier,\n    VotingClassifier\n)\nfrom sklearn.metrics import (\n    accuracy_score,\n    f1_score,\n    precision_score,\n    recall_score,\n    make_scorer,\n    classification_report\n)\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.impute import KNNImputer, SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (\n    BatchNormalization,\n    Flatten,\n    Dense,\n    Dropout,\n    Activation,\n)\nfrom keras import backend as K\nimport keras_tuner\nfrom keras_tuner import RandomSearch, Hyperband\n\nfrom pathlib import Path\nimport logging\nfrom functools import partial\n\nimport optuna\nfrom optuna.samplers import CmaEsSampler\nfrom optuna.pruners import MedianPruner\nimport optuna.visualization as vis\n\nfrom catboost import CatBoostClassifier\nimport xgboost as xgb\nfrom lightgbm import LGBMClassifier\nfrom category_encoders import TargetEncoder, MEstimateEncoder\n\nimport requests\nimport holidays\nimport statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\n\nfrom scikeras.wrappers import KerasClassifier\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\n\nimport warnings\nimport re\nimport time\nimport logging\nfrom functools import partial\nfrom itertools import combinations\nfrom IPython.display import Image\n\nimport logging\n\n# Visualization settings\nplt.style.use('ggplot')\n%matplotlib inline\nmatplotlib.rcParams['figure.figsize'] = (12, 8)\nsns.set_context(\"notebook\", font_scale=1.2)\nsns.set_style(\"whitegrid\")\n\n# Pandas settings\npd.options.mode.chained_assignment = None\n\n# Logging configuration\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Warnings configuration\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.496Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Setting\n\n","metadata":{}},{"cell_type":"code","source":"def plot_numerical_features(df):\n    num_features = df.select_dtypes(include=[np.number]).columns\n    ncols = 2\n    nrows = (len(num_features) + ncols - 1) // ncols\n\n    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 6 * nrows))\n    axes = axes.flatten()\n\n    for i, feature in enumerate(num_features):\n        sns.histplot(df[feature], bins=30, kde=True, ax=axes[i], color='skyblue', edgecolor='black')\n        axes[i].set_title(f'Distribution of {feature}', fontsize=18, fontweight='bold')\n        axes[i].set_xlabel(feature, fontsize=14)\n        axes[i].set_ylabel('Frequency', fontsize=14)\n        axes[i].grid(True, linestyle='--', alpha=0.7)  \n\n        mean_value = df[feature].mean()\n        axes[i].axvline(mean_value, color='red', linestyle='--', label='Mean')\n        axes[i].legend()\n\n    plt.tight_layout()\n    plt.show()\n\ndef plot_numerical_boxplots(df):\n    num_features = df.select_dtypes(include=[np.number]).columns\n    ncols = 2\n    nrows = (len(num_features) + ncols - 1) // ncols\n\n    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 6 * nrows))\n    axes = axes.flatten()\n\n    for i, feature in enumerate(num_features):\n        sns.boxplot(x=df[feature], ax=axes[i], color='lightgreen')\n        axes[i].set_title(f'Boxplot of {feature}', fontsize=18, fontweight='bold')\n        axes[i].set_xlabel(feature, fontsize=14)\n        axes[i].grid(True, linestyle='--', alpha=0.7)  \n\n        median_value = df[feature].median()\n        axes[i].axvline(median_value, color='orange', linestyle='--', label='Median')\n        axes[i].legend()\n\n    plt.tight_layout()\n    plt.show()\n\ndef plot_qq_plot(df):\n    num_features = df.select_dtypes(include=[np.number]).columns\n    ncols = 2\n    nrows = (len(num_features) + ncols - 1) // ncols\n\n    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 6 * nrows))\n    axes = axes.flatten()\n\n    for i, feature in enumerate(num_features):\n        stats.probplot(df[feature], dist=\"norm\", plot=axes[i])\n        axes[i].set_title(f'QQ Plot of {feature}', fontsize=18, fontweight='bold')\n        axes[i].set_xlabel('Theoretical Quantiles', fontsize=14)\n        axes[i].set_ylabel('Sample Quantiles', fontsize=14)\n        axes[i].grid(True, linestyle='--', alpha= 0.7)  \n\n    plt.tight_layout()\n    plt.show()\n\ndef plot_correlation_matrix(df, method='spearman'):\n    num_df = df.select_dtypes(include=[np.number])\n    \n    corr = num_df.corr(method=method)\n    plt.figure(figsize=(14, 10))\n    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, cbar_kws={\"shrink\": .8}, linewidths=.5)\n    plt.title(f'Correlation Matrix ({method.capitalize()} Correlation)', fontsize=18, fontweight='bold')\n    plt.xticks(fontsize=12)\n    plt.yticks(fontsize=12)\n    plt.show()\n\ndef plot_pairplot(df):\n    num_features = df.select_dtypes(include=[np.number]).columns\n    sns.pairplot(df[num_features], diag_kind='kde', plot_kws={'alpha': 0.6, 'edgecolor': 'k'}, height=2.5)\n    plt.suptitle('Pairplot of Numerical Features', y=1.02, fontsize=18, fontweight='bold')\n    plt.show()\n\ndef plot_categorical_features(df, ncols=2, top_n=None):\n    cat_features = df.select_dtypes(include=[object]).columns\n    nrows = (len(cat_features) + ncols - 1) // ncols\n\n    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(14, 6 * nrows))\n    axes = axes.flatten()\n\n    for i, feature in enumerate(cat_features):\n        if top_n is not None:\n            top_categories = df[feature].value_counts().nlargest(top_n).index\n            sns.countplot(data=df[df[feature].isin(top_categories)], y=feature, ax=axes[i], palette='viridis', order=top_categories)\n        else:\n            sns.countplot(data=df, y=feature, ax=axes[i], palette='viridis')\n        \n        axes[i].set_title(f'Count of {feature}', fontsize=18, fontweight='bold')\n        axes[i].set_xlabel('Count', fontsize=14)\n        axes[i].set_ylabel(feature, fontsize=14)\n        axes[i].tick_params(axis='y', rotation=0)\n        axes[i].grid(True, linestyle='--', alpha=0.7)  \n    for j in range(i + 1, len(axes)):\n        fig.delaxes(axes[j])\n\n    plt.tight_layout()\n    plt.show()\n\ndef PolynomialFeatures_labeled(input_df,power):\n   \n    poly = preprocessing.PolynomialFeatures(power)\n    output_nparray = poly.fit_transform(input_df)\n    powers_nparray = poly.powers_\n\n    input_feature_names = list(input_df.columns)\n    target_feature_names = [\"Constant Term\"]\n    for feature_distillation in powers_nparray[1:]:\n        intermediary_label = \"\"\n        final_label = \"\"\n        for i in range(len(input_feature_names)):\n            if feature_distillation[i] == 0:\n                continue\n            else:\n                variable = input_feature_names[i]\n                power = feature_distillation[i]\n                intermediary_label = \"%s+%d\" % (variable,power)\n                if final_label == \"\":         #If the final label isn't yet specified\n                    final_label = intermediary_label\n                else:\n                    final_label = final_label + \"x\" + intermediary_label\n        target_feature_names.append(final_label)\n    output_df = pd.DataFrame(output_nparray, columns = target_feature_names)\n    return output_df\n\ndef variance_threshold(df,th):\n    var_thres=VarianceThreshold(threshold=th)\n    var_thres.fit(df)\n    new_cols = var_thres.get_support()\n    return df.iloc[:,new_cols]\n   \ndef optimize_memory_usage(df, print_size=True):\n    \"\"\"\n    Optimizes memory usage in a DataFrame by downcasting numeric columns.\n\n    Parameters:\n        df (pd.DataFrame): The DataFrame to optimize.\n        print_size (bool): If True, prints memory usage before and after optimization.\n\n    Returns:\n        pd.DataFrame: The optimized DataFrame.\n    \"\"\"\n    # Types for optimization.\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    \n    # Memory usage size before optimize (Mb).\n    before_size = df.memory_usage().sum() / 1024**2\n    \n    for column in df.columns:\n        column_type = df[column].dtype\n        \n        if column_type in numerics:\n            try:\n                if str(column_type).startswith('int'):\n                    df[column] = pd.to_numeric(df[column], downcast='integer')\n                else:\n                    df[column] = pd.to_numeric(df[column], downcast='float')\n                logger.info(f\"Optimized column {column}: {column_type} -> {df[column].dtype}\")\n            except Exception as e:\n                logger.error(f\"Failed to optimize column {column}: {e}\")\n    \n    # Memory usage size after optimize (Mb).\n    after_size = df.memory_usage().sum() / 1024**2\n    \n    if print_size:\n        print(\n            'Memory usage size: before {:5.4f} Mb - after {:5.4f} Mb ({:.1f}%).'.format(\n                before_size, after_size, 100 * (before_size - after_size) / before_size\n            )\n        )\n    \n    return df\n\ndef categorize_variable(df, column, labels):\n    \n    if len(labels) != 3:\n        raise ValueError(\"3 type\")\n    \n    bins = [-float('inf'), \n            df[column].quantile(0.25), \n            df[column].quantile(0.75), \n            float('inf')]\n    \n    df[f'{column}_group'] = pd.cut(df[column], bins=bins, labels=labels)\n    return df\n\ndef replace_outliers_with_mean(df, threshold=3):\n\n    df_clean = df.copy()\n    \n    numeric_cols = df.select_dtypes(include=[np.number]).columns\n    \n    for col in numeric_cols:\n        \n        z_scores = np.abs(stats.zscore(df[col], nan_policy='omit')) \n        \n        mean_val = df[col][z_scores <= threshold].mean()\n        \n        df_clean[col] = np.where(z_scores > threshold, mean_val, df[col])\n        \n    return df_clean","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.496Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s5e7/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s5e7/test.csv')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.496Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Information","metadata":{}},{"cell_type":"code","source":"display(train.shape, test.shape)\n\ndisplay(train.info())\ndisplay(test.info())\n\ntest = test.drop(['id'], axis =1)\ntrain = train.drop(['id'], axis =1)\n\ndisplay(train.head(5))\ndisplay(test.head(5))\n\ndisplay(train.describe().T)\n\nduplicates = train.duplicated()\nprint(f\"Number of duplicates: {duplicates.sum()}\")\n\nfor col in train.columns:\n    pct_missing = np.mean(train[col].isnull())\n    print('{} - {}%'.format(col, round(pct_missing*100)))\n\nduplicates = test.duplicated()\nprint(f\"Number of duplicates: {duplicates.sum()}\")\n\nfor col in test.columns:\n    pct_missing = np.mean(test[col].isnull())\n    print('{} - {}%'.format(col, round(pct_missing*100)))\n\ntrain = optimize_memory_usage(train)\ntest = optimize_memory_usage(test)\n\ntrain_df = train.copy()\ntest_df = test.copy()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sdv.metadata import SingleTableMetadata\nfrom sdv.single_table import CTGANSynthesizer\nfrom sdv.metadata import Metadata\n\nmetadata = Metadata.detect_from_dataframe(\n    data=train,\n    table_name='introvert')\n\n\nsynthesizer = CTGANSynthesizer(metadata=metadata)\n\nsynthesizer.fit(train)\n\nsynthetic_data = synthesizer.sample(num_rows=5000)\n\ntrain = pd.concat([train, synthetic_data])\n\nprint(train.shape)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.496Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"duplicates = train.duplicated()\nprint(f\"Number of duplicates: {duplicates.sum()}\")\n\ntrain = train.drop_duplicates()\n\nduplicates = train.duplicated()\nprint(f\"Number of duplicates: {duplicates.sum()}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.498Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"## Numerical feature","metadata":{}},{"cell_type":"markdown","source":"### Hit","metadata":{}},{"cell_type":"code","source":"plot_numerical_features(train)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.498Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Boxplot","metadata":{}},{"cell_type":"code","source":"plot_numerical_boxplots(train)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.498Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Q-Q plot\n","metadata":{}},{"cell_type":"code","source":"plot_qq_plot(train)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.499Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Correlation matrix","metadata":{}},{"cell_type":"code","source":"plot_correlation_matrix(train)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.499Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Categorical features","metadata":{}},{"cell_type":"code","source":"plot_categorical_features(train)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.5Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Nan","metadata":{}},{"cell_type":"code","source":"num_cols = test.select_dtypes(include=['number']).columns\ncat_cols = test.select_dtypes(include=['object', 'category']).columns","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.5Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_imputer = IterativeImputer(random_state=42)\ntrain[num_cols] = num_imputer.fit_transform(train[num_cols])\ntest[num_cols] = num_imputer.transform(test[num_cols])\n\nfor col in cat_cols:\n    mode_val = train[col].mode()[0]\n    train[col] = train[col].fillna(mode_val)\n    test[col] = test[col].fillna(mode_val)\n\ntrain.shape, test.shape","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.5Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in train.columns:\n    pct_missing = np.mean(train[col].isnull())\n    print('{} - {}%'.format(col, round(pct_missing*100)))\n\nduplicates = test.duplicated()\nprint(f\"Number of duplicates: {duplicates.sum()}\")\n\nfor col in test.columns:\n    pct_missing = np.mean(test[col].isnull())\n    print('{} - {}%'.format(col, round(pct_missing*100)))","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.5Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# New features","metadata":{}},{"cell_type":"code","source":"categorize_variable(train, 'Time_spent_Alone', [\"min\", \"mean\", \"max\"])\ncategorize_variable(test, 'Time_spent_Alone', [\"min\", \"mean\", \"max\"])\ncategorize_variable(train, 'Social_event_attendance', [\"low\", \"medium\", \"high\"])\ncategorize_variable(test, 'Social_event_attendance', [\"low\", \"medium\", \"high\"])\ncategorize_variable(train, 'Going_outside', [\"No\", \"Maybe\", \"Yes\"])\ncategorize_variable(test, 'Going_outside', [\"No\", \"Maybe\", \"Yes\"])\ncategorize_variable(train, 'Friends_circle_size', [\"low\", \"medium\", \"high\"])\ncategorize_variable(test, 'Friends_circle_size', [\"low\", \"medium\", \"high\"])\ncategorize_variable(train, 'Post_frequency', [\"low\", \"medium\", \"high\"])\ncategorize_variable(test, 'Post_frequency', [\"low\", \"medium\", \"high\"])\n\ntrain.shape, test.shape","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.5Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_features(df, train_stats=None):\n        if train_stats is None:\n            train_stats = {\n                'post_median': df['Post_frequency'].median()\n            }\n        \n        df['Social_Activity_Index'] = df['Social_event_attendance'] * df['Friends_circle_size']\n        df['Isolation_Score'] = df['Time_spent_Alone'] / (df['Going_outside'] + 1)\n        df['Social_Balance'] = df['Social_event_attendance'] - df['Time_spent_Alone']\n        df['Log_Friends'] = np.log1p(df['Friends_circle_size'])\n        \n        if 'Post_frequency' in df.columns:\n            df['High_Posting'] = (df['Post_frequency'] > train_stats['post_median']).astype(int)\n        \n        return df\n\ncreate_features(train)\ncreate_features(test)\n\ntrain.shape, test.shape","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.501Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# X,y make transform","metadata":{}},{"cell_type":"code","source":"col = ['Stage_fear', 'Drained_after_socializing']\n\nfor c in col:\n    train[c] = train[c].astype('category')\n    test[c] = test[c].astype('category')\n\nle = LabelEncoder()\ntrain['Personality'] = le.fit_transform(train['Personality'])\n\nX = train.drop(columns=['Personality'])\ny = train['Personality']\n\ndisplay(X.shape, y.shape, test.shape)\n\nnumeric_cols = X.select_dtypes(include=['number']).columns\ncategorical_cols = X.select_dtypes(exclude=['number']).columns\n\nnum_imputer = SimpleImputer(strategy='mean')\nX[numeric_cols] = num_imputer.fit_transform(X[numeric_cols])\ntest[numeric_cols] = num_imputer.transform(test[numeric_cols])\n\ncat_imputer = SimpleImputer(strategy='most_frequent')\nX[categorical_cols] = cat_imputer.fit_transform(X[categorical_cols])\ntest[categorical_cols] = cat_imputer.transform(test[categorical_cols])\n\ndisplay(X.info(), test.info())\n\ncat_cols = X.select_dtypes(include=['category', 'object']).columns.tolist()\n\nencoder = OneHotEncoder(drop='first', sparse_output=False)  \n\nX_encoded = encoder.fit_transform(X[cat_cols])\nX_encoded = pd.DataFrame(\n    X_encoded,\n    columns=encoder.get_feature_names_out(cat_cols)\n)\nX = pd.concat([\n    X.drop(columns=cat_cols).reset_index(drop=True),  \n    X_encoded                  \n], axis=1)\n\ntest_encoded = encoder.fit_transform(test[cat_cols])\ntest_encoded = pd.DataFrame(\n    test_encoded,\n    columns=encoder.get_feature_names_out(cat_cols)\n)\ntest = pd.concat([\n    test.drop(columns=cat_cols),  \n    test_encoded                  \n], axis=1)\n\ndisplay(X.info(), test.info())\n\nsmote = KMeansSMOTE(\n    kmeans_estimator=MiniBatchKMeans(n_init=3, random_state=0), random_state=42\n)\nX, y = smote.fit_resample(X, y)\ndisplay(X.shape, y.shape, test.shape)\n\nX_pol = PolynomialFeatures_labeled(X, 2)\ntest_pol = PolynomialFeatures_labeled(test, 2)\n\nn_components = 2\n\npca = PCA(n_components=n_components)\n\npca_components = pca.fit_transform(X_pol)\npca_components_test = pca.transform(test_pol)\n\npca_df = pd.DataFrame(pca_components, columns=[f'PCA_{i+1}' for i in range(n_components)])\nX = pd.concat([X, pca_df], axis=1)\n\npca_df_test = pd.DataFrame(pca_components_test, columns=[f'PCA_{i+1}' for i in range(n_components)])\ntest = pd.concat([test, pca_df_test], axis=1)\n\nX = variance_threshold(X,0.02)\nlist_name = (X.columns)\ntest = test[list_name]\n\ndisplay(X.shape, y.shape, test.shape)\n\nscaler = RobustScaler()\n\nX[X.select_dtypes(include=[np.number]).columns] = scaler.fit_transform(X[X.select_dtypes(include=[np.number]).columns])\ntest[X.select_dtypes(include=[np.number]).columns] = scaler.transform(test[X.select_dtypes(include=[np.number]).columns])","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.501Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Fit parametrs","metadata":{}},{"cell_type":"code","source":"logging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ndef optimize_model(X, y, model_type='xgb', n_trials=50):\n    \n    def objective(trial):\n        try:\n            if model_type == 'xgb':\n                params = {\n                    'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n                    'max_depth': trial.suggest_int('max_depth', 3, 12),\n                    'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n                    'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n                    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n                    'gamma': trial.suggest_float('gamma', 0, 1),\n                    'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n                    'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n                    'use_label_encoder': False,\n                    'eval_metric': 'logloss',\n                    'random_state': 42\n                }\n                model = xgb.XGBClassifier(**params)\n                \n            elif model_type == 'lgb':\n                params = {\n                    'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n                    'max_depth': trial.suggest_int('max_depth', 3, 12),\n                    'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n                    'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n                    'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n                    'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n                    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n                    'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n                    'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n                    'random_state': 42,\n                }\n                model = LGBMClassifier(**params, verbose=-1,)\n                \n            elif model_type == 'cat':\n                params = {\n                    'iterations': trial.suggest_int('iterations', 100, 3000),\n                    'depth': trial.suggest_int('depth', 4, 10),\n                    'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.3, log=True),\n                    'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n                    'random_strength': trial.suggest_float('random_strength', 1e-9, 10, log=True),\n                    'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 1),\n                    'od_type': 'Iter',\n                    'od_wait': 100,\n                    'random_state': 42,\n                }\n                model = CatBoostClassifier(**params, verbose=0)\n                \n            elif model_type == 'rf':\n                params = {\n                    'n_estimators': trial.suggest_int('n_estimators', 100, 3000),\n                    'max_depth': trial.suggest_categorical('max_depth', [None, *range(3, 16)]),\n                    'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n                    'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n                    'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n                    'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n                    'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n                    'random_state': 42,\n                    'n_jobs': -1  \n                }\n                model = RandomForestClassifier(**params)\n            \n            score = cross_val_score(model, X, y, cv=3, scoring='accuracy', n_jobs=-1).mean()\n            return score\n        \n        except Exception as e:\n            logger.error(f\"Error during trial: {str(e)}\")\n            return float('-inf')  \n    \n    study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=42))\n    study.optimize(objective, n_trials=n_trials, show_progress_bar=True)\n    \n    logger.info(f\"Best {model_type} params: {study.best_params}\")\n    logger.info(f\"Best {model_type} accuracy: {study.best_value:.4f}\")\n    \n    return study.best_params\n\nmodels_params = {\n    'xgb': optimize_model(X, y, 'xgb', n_trials=100),\n    'lgb': optimize_model(X, y, 'lgb', n_trials=100),\n    'cat': optimize_model(X, y, 'cat', n_trials=100),\n    'rf': optimize_model(X, y, 'rf', n_trials=100)\n}","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.501Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"## Set model","metadata":{}},{"cell_type":"code","source":"def create_ensemble_binary(X, y, test, n_folds=5,\n                         catboost_params=None, xgb_params=None, lgbm_params=None, \n                         rf_params=None): \n    \"\"\"\n    Create ensemble for binary classification with standard metrics.\n    \n    Parameters:\n    -----------\n    X : pd.DataFrame\n        Training features\n    y : pd.Series (binary: 0/1)\n        Training target\n    test : pd.DataFrame\n        Test features\n    n_folds : int\n        Number of cross-validation folds\n    catboost_params : list of dict\n        Parameters for CatBoost models\n    xgb_params : list of dict\n        Parameters for XGBoost models\n    lgbm_params : list of dict\n        Parameters for LightGBM models\n    rf_params : list of dict  # ÐÐ¾Ð²Ñ‹Ð¹ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€\n        Parameters for RandomForest models\n        \n    Returns:\n    --------\n    tuple: (all_oof, all_test_preds, model_info)\n    \"\"\"\n    FOLDS = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n    \n    for col in cat_cols:\n        if col in X.columns:\n            X[col] = X[col].astype('category')\n            test[col] = test[col].astype('category')\n    \n    # Default parameters for binary classification\n    if catboost_params is None:\n        catboost_params = [{\n            'iterations': 1000,\n            'learning_rate': 0.05,\n            'depth': 6,\n            'l2_leaf_reg': 3,\n            'border_count': 64,\n            'verbose': 0,\n            'loss_function': 'Logloss',  \n            'random_state': 42\n        }]\n    \n    if xgb_params is None:\n        xgb_params = [{\n            'n_estimators': 500,\n            'learning_rate': 0.05,\n            'max_depth': 6,\n            'subsample': 0.8,\n            'colsample_bytree': 0.8,\n            'gamma': 0.1,\n            'min_child_weight': 3,\n            'objective': 'binary:logistic',  \n            'random_state': 42,\n            'enable_categorical': True\n        }]\n    \n    if lgbm_params is None:\n        lgbm_params = [{\n            'n_estimators': 500,\n            'learning_rate': 0.05,\n            'max_depth': -1,\n            'num_leaves': 31,\n            'subsample': 0.8,\n            'colsample_bytree': 0.8,\n            'objective': 'binary',  \n            'random_state': 42\n        }]\n    \n    if rf_params is None:\n        rf_params = [{\n            'n_estimators': 500,\n            'max_depth': None,\n            'min_samples_split': 2,\n            'min_samples_leaf': 1,\n            'max_features': 'sqrt',\n            'bootstrap': True,\n            'n_jobs': -1,\n            'random_state': 42\n        }]\n    \n    all_oof = {}\n    all_test_preds = {}\n    models_info = []\n    \n    # Create model instances\n    models = []\n    \n    # CatBoost\n    for i, params in enumerate(catboost_params, 1):\n        model_name = f'cat_{i}'\n        models.append((model_name, CatBoostClassifier(\n            **params, verbose=0,\n            cat_features=cat_cols if 'cat_features' in catboost_params[0] else None\n        )))\n        models_info.append({\n            'name': model_name,\n            'type': 'catboost',\n            'params': params\n        })\n    \n    # XGBoost\n    for i, params in enumerate(xgb_params, 1):\n        model_name = f'xgb_{i}'\n        models.append((model_name, xgb.XGBClassifier(\n            **params,\n        )))\n        models_info.append({\n            'name': model_name,\n            'type': 'xgboost',\n            'params': params\n        })\n    \n    # LightGBM\n    for i, params in enumerate(lgbm_params, 1):\n        model_name = f'lgb_{i}'\n        models.append((model_name, LGBMClassifier(\n            **params,verbose=-1,\n            categorical_feature=cat_cols if 'categorical_feature' in lgbm_params[0] else None\n        )))\n        models_info.append({\n            'name': model_name,\n            'type': 'lightgbm',\n            'params': params\n        })\n    \n    for i, params in enumerate(rf_params, 1):\n        model_name = f'rf_{i}'\n        models.append((model_name, RandomForestClassifier(**params)))\n        models_info.append({\n            'name': model_name,\n            'type': 'randomforest',\n            'params': params\n        })\n    \n    # Train models\n    for name, model in models:\n        print(f\"\\nTraining {name}...\")\n        oof_preds = np.zeros(len(X))\n        test_preds = np.zeros(len(test))\n        \n        for fold, (trn_idx, val_idx) in enumerate(FOLDS.split(X, y)):\n            X_train, y_train = X.iloc[trn_idx], y.iloc[trn_idx]\n            X_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n            \n            try:\n                if name.startswith('rf_'):\n                    X_train_fold = X_train.copy()\n                    X_val_fold = X_val.copy()\n                    test_fold = test.copy()\n                    \n                    for col in cat_cols:\n                        if col in X_train_fold.columns:\n                            X_train_fold[col] = X_train_fold[col].astype('category').cat.codes\n                            X_val_fold[col] = X_val_fold[col].astype('category').cat.set_categories(\n                                X_train_fold[col].cat.categories\n                            ).cat.codes\n                            test_fold[col] = test_fold[col].astype('category').cat.set_categories(\n                                X_train_fold[col].cat.categories\n                            ).cat.codes\n                    \n                    model.fit(X_train_fold, y_train)\n                    oof_preds[val_idx] = model.predict_proba(X_val_fold)[:, 1]\n                    test_preds += model.predict_proba(test_fold)[:, 1] / FOLDS.n_splits\n                \n                else:\n                    if name.startswith('cat_'):\n                        model.fit(X_train, y_train, eval_set=(X_val, y_val), verbose=0)\n                    else:\n                        model.fit(X_train, y_train)\n                    \n                    oof_preds[val_idx] = model.predict_proba(X_val)[:, 1]\n                    test_preds += model.predict_proba(test)[:, 1] / FOLDS.n_splits\n                \n                pred_labels = (oof_preds[val_idx] > 0.5).astype(int)\n                acc = accuracy_score(y_val, pred_labels)\n                prec = precision_score(y_val, pred_labels)\n                rec = recall_score(y_val, pred_labels)\n                f1 = f1_score(y_val, pred_labels)\n                \n                print(f\"{name} - Fold {fold+1}: \"\n                      f\"Acc={acc:.4f}, Prec={prec:.4f}, Rec={rec:.4f}, F1={f1:.4f}\")\n            \n            except Exception as e:\n                print(f\"Error in {name} Fold {fold+1}: {str(e)}\")\n                continue\n        \n        all_oof[name] = oof_preds\n        all_test_preds[name] = test_preds\n        \n        final_preds = (oof_preds > 0.5).astype(int)\n        print(f\"\\n{name} - Final OOF Metrics:\")\n        print(f\"Accuracy: {accuracy_score(y, final_preds):.4f}\")\n        print(f\"Precision: {precision_score(y, final_preds):.4f}\")\n        print(f\"Recall: {recall_score(y, final_preds):.4f}\")\n        print(f\"F1-score: {f1_score(y, final_preds):.4f}\")\n        print(\"=\"*50)\n    \n    return all_oof, all_test_preds, models_info","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.502Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Fit","metadata":{}},{"cell_type":"code","source":"optimized_cat_params = [models_params['cat']]\noptimized_xgb_params = [models_params['xgb']]\noptimized_lgbm_params = [models_params['lgb']]\noptimized_rf_params = [models_params['rf']]  \noof_results, test_predictions, models_info = create_ensemble_binary(\n    X, y, test,\n    catboost_params=optimized_cat_params,\n    xgb_params=optimized_xgb_params,\n    lgbm_params=optimized_lgbm_params,\n    rf_params=optimized_rf_params  \n)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.502Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"oof_results","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_predictions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Stack","metadata":{}},{"cell_type":"code","source":"def stack_predictions(oof_results, test_predictions, y_true):\n    X_stack = np.zeros((len(y_true), len(oof_results)))\n    for i, (name, preds) in enumerate(oof_results.items()):\n        if preds.ndim == 1:\n            X_stack[:, i] = preds\n        else:\n            X_stack[:, i] = preds[:, 1]\n    \n    X_test_stack = np.zeros((test_predictions[list(test_predictions.keys())[0]].shape[0], len(test_predictions)))\n    for i, (name, preds) in enumerate(test_predictions.items()):\n        if preds.ndim == 1:\n            X_test_stack[:, i] = preds\n        else:\n            X_test_stack[:, i] = preds[:, 1]\n    \n    X_train, X_val, y_train, y_val = train_test_split(\n        X_stack, y_true, test_size=0.2, random_state=42, stratify=y_true\n    )\n    \n    meta_clf = CatBoostClassifier(\n        iterations=3000,\n        learning_rate=0.01,\n        depth=4,\n        eval_metric='Accuracy',\n        verbose=0,\n        early_stopping_rounds=50,\n        random_state=42\n    )\n    \n    meta_clf.fit(\n        X_train, y_train,\n        eval_set=(X_val, y_val),\n        use_best_model=True\n    )\n    \n    full_train_preds = meta_clf.predict_proba(X_stack)\n    test_pred_proba = meta_clf.predict_proba(X_test_stack)\n    \n    val_pred = meta_clf.predict(X_val)\n    val_acc = accuracy_score(y_val, val_pred)\n    print(f\"\\nMeta-model Validation Accuracy: {val_acc:.4f}\")\n    \n    return full_train_preds, test_pred_proba, meta_clf\n\ntrain_meta_preds, test_meta_preds, meta_model = stack_predictions(oof_results, test_predictions, y)\n\nif train_meta_preds.shape[1] == 2:\n    train_meta_proba = train_meta_preds[:, 1]\n    test_meta_proba = test_meta_preds[:, 1]\n\ndef find_optimal_threshold(y_true, y_pred_proba):\n    thresholds = np.linspace(0.3, 0.7, 50)\n    best_f1 = 0\n    best_thresh = 0.5\n    for thresh in thresholds:\n        preds = (y_pred_proba > thresh).astype(int)\n        f1 = f1_score(y_true, preds)\n        if f1 > best_f1:\n            best_f1 = f1\n            best_thresh = thresh\n    return best_thresh\n\noptimal_threshold = find_optimal_threshold(y, train_meta_proba)\nblended_test_labels = (test_meta_proba > optimal_threshold).astype(int)\nprint(f\"Used optimal threshold: {optimal_threshold:.4f}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.503Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"sample = pd.read_csv('/kaggle/input/playground-series-s5e7/sample_submission.csv')\nsample['Personality'] = le.inverse_transform(blended_test_labels)\nsample.to_csv('submission.csv', index=False)\nsample.head(10)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-07-21T10:59:32.503Z"}},"outputs":[],"execution_count":null}]}